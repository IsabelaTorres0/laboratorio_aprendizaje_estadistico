{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70086771-ad90-497d-9b51-22626c9cce63",
   "metadata": {
    "id": "70086771-ad90-497d-9b51-22626c9cce63"
   },
   "source": [
    "# Laboratorio de regresión - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f666e0e-9e63-49f4-96e1-053c5b1738c3",
   "metadata": {
    "id": "9f666e0e-9e63-49f4-96e1-053c5b1738c3"
   },
   "source": [
    "|                |   |\n",
    ":----------------|---|\n",
    "| **Nombre**     | Iaabela Torres -Septien Uribe |\n",
    "| **Fecha**      | 15 de septiembre 2025  |\n",
    "| **Expediente** | 730667  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f352dc-5863-4685-af3c-25f8fcf60841",
   "metadata": {
    "id": "19f352dc-5863-4685-af3c-25f8fcf60841"
   },
   "source": [
    "## Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "235129d5-231a-478d-9998-76939af2c9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20677642-c94e-469c-8739-1f38869ae655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73fccec-9651-4f74-9d56-a3c2b2097e19",
   "metadata": {
    "id": "b73fccec-9651-4f74-9d56-a3c2b2097e19"
   },
   "source": [
    "Hemos estado usando `train_test_split` en nuestros modelos anteriores.\n",
    "\n",
    "¿Por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fe97ab-a033-4d0f-ab73-0cdabe591655",
   "metadata": {
    "id": "84fe97ab-a033-4d0f-ab73-0cdabe591655"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20b452d0-e0b5-4d92-bd1a-288fa14a2ed9",
   "metadata": {
    "id": "20b452d0-e0b5-4d92-bd1a-288fa14a2ed9"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a60a028-ed60-4a5c-9308-dee4862e2bac",
   "metadata": {
    "id": "0a60a028-ed60-4a5c-9308-dee4862e2bac"
   },
   "source": [
    "Si la muestra es un subset de la población y queremos generalizar sobre la población, ¿no sería mejor utilizar todos los datos al entrenar un modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50989a32-59e7-4bef-9b60-89f543d8ca81",
   "metadata": {
    "id": "50989a32-59e7-4bef-9b60-89f543d8ca81"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed8b1ad0-3c68-4f6a-b16b-c0b1353d7dd2",
   "metadata": {
    "id": "ed8b1ad0-3c68-4f6a-b16b-c0b1353d7dd2"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b98d96f3-7370-4161-aa67-75f10e5817cd",
   "metadata": {
    "id": "b98d96f3-7370-4161-aa67-75f10e5817cd"
   },
   "source": [
    "El propósito de volver a muestrear dentro de nuestro dataset es tener una idea de qué tan buena podría ser la generalización de nuestro modelo. Imagina un dataset ya separado en dos mitades. Utilizas la primera mitad para entrenar el modelo y pruebas en la segunda mitad; la segunda mitad eran datos invisibles para el modelo al momento de entrenar. Esto nos lleva a tres escenario típicos:\n",
    "\n",
    "1. Si el modelo hace buenas predicciones en la segunda mitad, significa que la primera mitad era \"suficiente\" para generalizar.\n",
    "2. Si el modelo no hace buenas predicciones en la segunda mitad, pero sí en la primera mitad, podría ser que había información importante en la segunda mitad que debió haber sido tomada en cuenta al entrenar, o un problema de overfitting.\n",
    "3. Si el modelo no hace buenas predicciones en la segunda mitad, y tampoco en la primera mitad, se tendrían que revisar los factores y/o el modelo seleccionado.\n",
    "\n",
    "El caso ideal sería el 1, pero por estadística los errores y varianzas tienen como entrada el número de muestas, por lo que tenemos menos seguridad de nuestros resutados al usar menos muestras. Si vemos que el modelo generaliza bien podemos unir de nuevo el dataset y entrenar sobre el dataset completo.\n",
    "\n",
    "En el caso 2 está el problema de que no podemos saber qué información es necesaria para el entrenamiento apropiado del modelo; esto nos lleva a pensar que debemos usar el dataset completo para entrenar, pero esto nos lleva al mismo problema de no saber si el modelo puede generalizar.\n",
    "\n",
    "El problema sólo incrementa si se tienen hiperparámetros en el modelo (e.g. $\\lambda$ en regularización)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16176ad-41fc-4f3c-b865-2eb4219152e2",
   "metadata": {
    "id": "a16176ad-41fc-4f3c-b865-2eb4219152e2"
   },
   "source": [
    "## Leave-One-Out Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f7165d-5b5d-4e92-ae7f-7edb12eea745",
   "metadata": {
    "id": "e1f7165d-5b5d-4e92-ae7f-7edb12eea745"
   },
   "source": [
    "Este método de validación es una colección de $n$ `train-test-split`. Teniendo un dataset de $n$ muestras, la lógica es:\n",
    "1. Saca una muestra del dataset.\n",
    "2. Entrena tu modelo con las $n-1$ muestras.\n",
    "3. Evalúa tu modelo en la muestra que quedó fuera con el métrico que más se ajuste a la aplicación.\n",
    "4. Regresa la muestra al dataset.\n",
    "5. Repite 1-4 con muestras diferentes hasta haber hecho el procedimiento $n$ veces para $n$ muestras.\n",
    "6. Calcula la media y desviación estándar de los métricos guardados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21340b80-8fa4-4cdf-8fe4-85e4a35febcd",
   "metadata": {
    "id": "21340b80-8fa4-4cdf-8fe4-85e4a35febcd"
   },
   "source": [
    "Con los resultados del proceso de validación podemos saber qué tan bueno podría ser el modelo seleccionado con los datos (con/sin transformaciones)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0983bf1c-a6a2-42e4-a522-92bba6b450ab",
   "metadata": {
    "id": "0983bf1c-a6a2-42e4-a522-92bba6b450ab"
   },
   "source": [
    "### Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e5f076-bc52-482c-9560-ecd0c125efa7",
   "metadata": {
    "id": "21e5f076-bc52-482c-9560-ecd0c125efa7"
   },
   "source": [
    "Utiliza el dataset `Motor Trend Car Road Tests`. Elimina la columna `model` y entrena 32 modelos diferentes utilizando Leave-One-Out Cross Validation con target `mpg`. Utiliza MSE como métrico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1pZue3u0jSir",
   "metadata": {
    "id": "1pZue3u0jSir"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7199ca1-32f0-463b-925f-76613d608a72",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "b7199ca1-32f0-463b-925f-76613d608a72",
    "outputId": "e4eeefc9-b3ba-4175-c5e6-7282ecec2ebc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>30.4</td>\n",
       "      <td>4</td>\n",
       "      <td>95.1</td>\n",
       "      <td>113</td>\n",
       "      <td>3.77</td>\n",
       "      <td>1.513</td>\n",
       "      <td>16.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15.8</td>\n",
       "      <td>8</td>\n",
       "      <td>351.0</td>\n",
       "      <td>264</td>\n",
       "      <td>4.22</td>\n",
       "      <td>3.170</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>19.7</td>\n",
       "      <td>6</td>\n",
       "      <td>145.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.62</td>\n",
       "      <td>2.770</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>301.0</td>\n",
       "      <td>335</td>\n",
       "      <td>3.54</td>\n",
       "      <td>3.570</td>\n",
       "      <td>14.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>21.4</td>\n",
       "      <td>4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>109</td>\n",
       "      <td>4.11</td>\n",
       "      <td>2.780</td>\n",
       "      <td>18.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mpg  cyl   disp   hp  drat     wt  qsec  vs  am  gear  carb\n",
       "27  30.4    4   95.1  113  3.77  1.513  16.9   1   1     5     2\n",
       "28  15.8    8  351.0  264  4.22  3.170  14.5   0   1     5     4\n",
       "29  19.7    6  145.0  175  3.62  2.770  15.5   0   1     5     6\n",
       "30  15.0    8  301.0  335  3.54  3.570  14.6   0   1     5     8\n",
       "31  21.4    4  121.0  109  4.11  2.780  18.6   1   1     4     2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"Motor Trend Car Road Tests.xlsx\")\n",
    "data = data.drop(columns = ['model'])\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "wHLEveqele40",
   "metadata": {
    "id": "wHLEveqele40"
   },
   "outputs": [],
   "source": [
    "x = data.drop(columns = ['mpg'])\n",
    "y = data['mpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40ad85dc-3106-4430-9ed2-b6354e00d87f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40ad85dc-3106-4430-9ed2-b6354e00d87f",
    "outputId": "149ac3fb-e7e9-4613-c3d2-e4ab8bc77531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE promedio: 12.181558006901941\n",
      "Desviación estándar: 17.067399871888586\n"
     ]
    }
   ],
   "source": [
    "mses = []\n",
    "\n",
    "for i in range(32):\n",
    "  x_train = x.drop(i).to_numpy()\n",
    "  x_test = x.iloc[i].to_numpy().reshape(1, -1)\n",
    "  y_train = y.drop(i).to_numpy()\n",
    "  y_test = y.iloc[i]\n",
    "\n",
    "  scaler = StandardScaler()\n",
    "  x_train = scaler.fit_transform(x_train)\n",
    "  x_test = scaler.transform(x_test)\n",
    "\n",
    "  lr = LinearRegression()\n",
    "  lr.fit(x_train, y_train)\n",
    "\n",
    "  y_pred = lr.predict(x_test)\n",
    "\n",
    "  mse = mean_squared_error([y_test], y_pred)\n",
    "  mses.append(mse)\n",
    "\n",
    "print(\"MSE promedio:\", np.mean(mses))\n",
    "print(\"Desviación estándar:\", np.std(mses))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8724bdb-e50b-4470-b53a-2d9843fae6ea",
   "metadata": {
    "id": "c8724bdb-e50b-4470-b53a-2d9843fae6ea"
   },
   "source": [
    "Interpreta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19904df-1fe6-433a-b1bd-a7ce86ce0eef",
   "metadata": {
    "id": "b19904df-1fe6-433a-b1bd-a7ce86ce0eef"
   },
   "source": [
    "El resultado muestra que el modelo tiene un error cuadrático medio (MSE) promedio de aproximadamente 12.18. Esto indica un error moderado. Sin embargo, la desviación estándar es de 17.07,Esto es bastante alto por lo que el modelo no será el más optimo o mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc61dd1-fa5f-43b0-969a-592f8e9fc56f",
   "metadata": {
    "id": "dbc61dd1-fa5f-43b0-969a-592f8e9fc56f"
   },
   "source": [
    "\n",
    "\n",
    "## K-Folds Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbca526-2c69-4c70-b6b4-270fc51d825b",
   "metadata": {
    "id": "2dbca526-2c69-4c70-b6b4-270fc51d825b"
   },
   "source": [
    "El dataset `Motor Trend Car Road Tests` sólo tiene 32 muestras, y utilizar un modelo sencillo de regresión múltiple hace que usar LOOCV sea muy rápido. El dataset `California Housing` tiene $20640$ muestras para $9$ columnas, entonces realizar un ajuste sobre una transformación o sobre el modelo y luego calcular el impacto esperado podría tomar más tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a437812-c00e-400f-ae7d-110b3afa5dc3",
   "metadata": {
    "id": "8a437812-c00e-400f-ae7d-110b3afa5dc3"
   },
   "source": [
    "La solución propuesta es dividir el dataset en *k* folds (partes iguales), ajustar en *k-1* folds y probar en el restante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb82cc3-0d35-442a-a12b-f9c6fd131af2",
   "metadata": {
    "id": "5bb82cc3-0d35-442a-a12b-f9c6fd131af2"
   },
   "source": [
    "### Ejercicio 2\n",
    "Utiliza el dataset `California Housing` y haz K-folds Cross Validation con 10 folds. Utiliza el MSE como métrico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ba50e361-edcd-4cdb-9609-68f20d6fca97",
   "metadata": {
    "id": "ba50e361-edcd-4cdb-9609-68f20d6fca97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (20640, 8) (20640,)\n",
      "Dataset Features: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
      "Dataset Target: ['MedHouseVal']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "print(\"Dataset Shape:\", housing.data.shape, housing.target.shape)\n",
    "print(\"Dataset Features:\", housing.feature_names)\n",
    "print(\"Dataset Target:\", housing.target_names)\n",
    "X = housing.data\n",
    "y = housing.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dfcb4a51-b02b-4bcb-8c81-c1d986c5464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "indices = np.arange(len(X))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "Xs = X[indices]\n",
    "ys = y[indices]\n",
    "\n",
    "lista1 = indices[1:2064]\n",
    "lista2 = indices[2064:4128]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "98695e09-69a8-46e3-9e82-57572ecd2036",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2215274097.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[100], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    folds[]\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "tam_seccion = len(indices) // num_secciones\n",
    "\n",
    "folds = []\n",
    "for i in range(10)\n",
    "    inicio = i * tam_seccion\n",
    "    fin = (i + 1) * tam_seccion\n",
    "    listas.append(indices[inicio:fin])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "21e506d2-cab7-4e5d-b5ae-34fa720f49ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista1 = indices[1:2064]\n",
    "lista2 = indices[2064:4128]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ac530600-2f30-43a6-a4db-cb2129534597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.6812</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.192201</td>\n",
       "      <td>1.022284</td>\n",
       "      <td>1392.0</td>\n",
       "      <td>3.877437</td>\n",
       "      <td>36.06</td>\n",
       "      <td>-119.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.5313</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.039384</td>\n",
       "      <td>1.193493</td>\n",
       "      <td>1565.0</td>\n",
       "      <td>2.679795</td>\n",
       "      <td>35.14</td>\n",
       "      <td>-119.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.4801</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3.977155</td>\n",
       "      <td>1.185877</td>\n",
       "      <td>1310.0</td>\n",
       "      <td>1.360332</td>\n",
       "      <td>37.80</td>\n",
       "      <td>-122.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.7376</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.163636</td>\n",
       "      <td>1.020202</td>\n",
       "      <td>1705.0</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>34.28</td>\n",
       "      <td>-118.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.7250</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.492991</td>\n",
       "      <td>1.028037</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>2.483645</td>\n",
       "      <td>36.62</td>\n",
       "      <td>-121.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>6.3700</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.129032</td>\n",
       "      <td>0.926267</td>\n",
       "      <td>658.0</td>\n",
       "      <td>3.032258</td>\n",
       "      <td>33.78</td>\n",
       "      <td>-117.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>3.0500</td>\n",
       "      <td>33.0</td>\n",
       "      <td>6.868597</td>\n",
       "      <td>1.269488</td>\n",
       "      <td>1753.0</td>\n",
       "      <td>3.904232</td>\n",
       "      <td>34.02</td>\n",
       "      <td>-117.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>2.9344</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.986717</td>\n",
       "      <td>1.079696</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>3.332068</td>\n",
       "      <td>34.03</td>\n",
       "      <td>-118.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>5.7192</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.395349</td>\n",
       "      <td>1.067979</td>\n",
       "      <td>1777.0</td>\n",
       "      <td>3.178891</td>\n",
       "      <td>37.58</td>\n",
       "      <td>-121.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.5755</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3.402576</td>\n",
       "      <td>1.058776</td>\n",
       "      <td>2619.0</td>\n",
       "      <td>2.108696</td>\n",
       "      <td>37.77</td>\n",
       "      <td>-122.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0     1         2         3       4         5      6       7\n",
       "0      1.6812  25.0  4.192201  1.022284  1392.0  3.877437  36.06 -119.01\n",
       "1      2.5313  30.0  5.039384  1.193493  1565.0  2.679795  35.14 -119.46\n",
       "2      3.4801  52.0  3.977155  1.185877  1310.0  1.360332  37.80 -122.44\n",
       "3      5.7376  17.0  6.163636  1.020202  1705.0  3.444444  34.28 -118.72\n",
       "4      3.7250  34.0  5.492991  1.028037  1063.0  2.483645  36.62 -121.93\n",
       "...       ...   ...       ...       ...     ...       ...    ...     ...\n",
       "20635  6.3700  35.0  6.129032  0.926267   658.0  3.032258  33.78 -117.96\n",
       "20636  3.0500  33.0  6.868597  1.269488  1753.0  3.904232  34.02 -117.43\n",
       "20637  2.9344  36.0  3.986717  1.079696  1756.0  3.332068  34.03 -118.38\n",
       "20638  5.7192  15.0  6.395349  1.067979  1777.0  3.178891  37.58 -121.96\n",
       "20639  2.5755  52.0  3.402576  1.058776  2619.0  2.108696  37.77 -122.42\n",
       "\n",
       "[20640 rows x 8 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5436ba54-d15e-4790-97d7-f177f4ef39fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4128.0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hacer un fold\n",
    "(20640/10)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c9d03224-0ab4-4ef7-8676-f4b7edb04d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "indices = np.arange(len(X))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "Xs = X[indices]\n",
    "ys = y[indices]\n",
    "\n",
    "lista1 = indices[1:2064]\n",
    "lista2 = indices[2064:4128]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e80808d7-9805-4bac-930c-405f0a429002",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tam_seccion = len(indices) // 10\n",
    "\n",
    "folds = []\n",
    "for i in range(10):\n",
    "    inicio = i * tam_seccion\n",
    "    fin = (i + 1) * tam_seccion\n",
    "    folds.append(indices[inicio:fin])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "13fa3d03-9be9-41e8-abd4-ef20d3810fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE promedio: 0.5270659954870702\n",
      "Desviación estándar: 0.022266703148739637\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mses = []\n",
    "for i in range(10):\n",
    "    inicio = i * tam_seccion\n",
    "    fin = (i + 1) * tam_seccion\n",
    "    \n",
    "    test_idx = indices[inicio:fin]\n",
    "    train_idx = np.concatenate((indices[:inicio], indices[fin:]))\n",
    "    \n",
    "    x_train = Xs[train_idx]\n",
    "    x_test = Xs[test_idx]\n",
    "    y_train = ys[train_idx]\n",
    "    y_test = ys[test_idx]\n",
    "\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = lr.predict(x_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mses.append(mse)\n",
    "\n",
    "print(\"MSE promedio:\", np.mean(mses))\n",
    "print(\"Desviación estándar:\", np.std(mses))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f7098f-a1de-4508-b3ff-af1484561856",
   "metadata": {
    "id": "34f7098f-a1de-4508-b3ff-af1484561856"
   },
   "source": [
    "El MSE es bastante bajo por lo tanto el error es muy bajo por lo tanto la regresión lineal es muy buena. EL error es de 0.5270 aproximadamente 0.53 por lo que se puede decir que es bastante bueno además de que la desviación estandar es muy baja siendo 0.022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fbaf4d-f62b-46d9-9a35-23fcdd50a8ca",
   "metadata": {
    "id": "b7fbaf4d-f62b-46d9-9a35-23fcdd50a8ca"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "333c8039-5b38-4835-a523-d4f6f7a7040b",
   "metadata": {
    "id": "333c8039-5b38-4835-a523-d4f6f7a7040b"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da5792ac-6d38-4f02-bf10-aeaa0a040d17",
   "metadata": {
    "id": "da5792ac-6d38-4f02-bf10-aeaa0a040d17"
   },
   "source": [
    "## Referencia\n",
    "\n",
    "James, G., Witten, D., Hastie, T., Tibshirani, R.,, Taylor, J. (2023). An Introduction to Statistical Learning with Applications in Python. Cham: Springer. ISBN: 978-3-031-38746-3"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
